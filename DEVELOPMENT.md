# Guia para Desenvolvedores

Este documento descreve como configurar o ambiente de desenvolvimento, contribuir para o projeto e realizar tarefas comuns de manuten√ß√£o.

## üìã √çndice

- [Ambiente de Desenvolvimento](#ambiente-de-desenvolvimento)
- [Fluxo de Trabalho](#fluxo-de-trabalho)
- [Padr√µes de C√≥digo](#padr√µes-de-c√≥digo)
- [Testes](#testes)
- [Atualizando os Scrapers](#atualizando-os-scrapers)
- [Integra√ß√£o com o Reposit√≥rio Alvo](#integra√ß√£o-com-o-reposit√≥rio-alvo)
- [Troubleshooting para Desenvolvedores](#troubleshooting-para-desenvolvedores)

## üõ†Ô∏è Ambiente de Desenvolvimento

### Pr√©-requisitos

- Node.js 20.x ou superior
- Git
- Ubuntu/Debian ou WSL para Windows
- Editor de c√≥digo (recomendado: VSCode)

### Configura√ß√£o Inicial

1. Clone o reposit√≥rio:

   ```bash
   git clone https://github.com/ApenasGabs/scraping-grupo-olx.git
   cd scraping-grupo-olx
   ```

2. Instale as depend√™ncias:

   ```bash
   npm install
   ```

3. Instale as depend√™ncias do sistema para o Puppeteer:

   ```bash
   sudo apt-get update
   sudo apt-get install -y xvfb libxss1 libgtk-3-0 libnotify-dev libnss3 libx11-xcb1
   ```

4. Configure o arquivo `.env`:

   ```bash
   cp .env.example .env
   ```

   Edite o arquivo `.env` com suas configura√ß√µes locais.

5. Crie pastas necess√°rias:

   ```bash
   mkdir -p data/results logs
   ```

### Scripts √öteis

O projeto inclui v√°rios scripts no `package.json` para facilitar o desenvolvimento:

- `npm run scrape`: Executa ambos os scrapers
- `npm run scrape:olx`: Executa apenas o scraper OLX
- `npm run scrape:zap`: Executa apenas o scraper ZAP
- `npm run lint`: Verifica problemas de c√≥digo com ESLint
- `npm run test`: Executa testes

## üîÑ Fluxo de Trabalho

1. **Atualize sua branch:**

   ```bash
   git checkout main
   git pull origin main
   ```

2. **Crie uma branch para sua feature/fix:**

   ```bash
   git checkout -b feature/nome-da-feature
   # ou
   git checkout -b fix/nome-do-bug
   ```

3. **Fa√ßa as altera√ß√µes necess√°rias**

4. **Teste suas mudan√ßas localmente:**

   ```bash
   npm run scrape
   ```

5. **Verifique se o c√≥digo segue os padr√µes:**

   ```bash
   npm run lint
   ```

6. **Commit suas altera√ß√µes:**

   ```bash
   git add .
   git commit -m "feat: descri√ß√£o da sua altera√ß√£o"
   ```

7. **Push para o GitHub:**

   ```bash
   git push origin feature/nome-da-feature
   ```

8. **Crie um Pull Request** para a branch `main`

## üìè Padr√µes de C√≥digo

Este projeto segue o padr√£o de commits do Conventional Commits e utiliza o ESLint para garantir a qualidade do c√≥digo.

### Conventional Commits

Os commits devem seguir o padr√£o:

```
<tipo>(<escopo opcional>): <descri√ß√£o>
```

Tipos comuns:

- `feat`: Nova funcionalidade
- `fix`: Corre√ß√£o de bug
- `docs`: Mudan√ßas na documenta√ß√£o
- `style`: Formata√ß√£o, ponto e v√≠rgula faltando, etc.
- `refactor`: Refatora√ß√£o de c√≥digo
- `test`: Adi√ß√£o ou corre√ß√£o de testes
- `chore`: Altera√ß√µes em ferramentas de build, depend√™ncias, etc.

### Estilo de C√≥digo

- Use 2 espa√ßos para indenta√ß√£o
- Linhas com no m√°ximo 100 caracteres
- Use aspas duplas para strings
- Adicione ponto e v√≠rgula ao final das declara√ß√µes
- Prefira arrow functions (`const fn = () => {}`)
- Use destructuring quando poss√≠vel

## üß™ Testes

### Executando Testes

```bash
npm run test
```

### Adicionando Novos Testes

Os testes est√£o localizados na pasta `tests/`. Para adicionar novos testes:

1. Crie um arquivo com o nome `[feature].test.js`
2. Siga o padr√£o existente para novos testes
3. Execute os testes para garantir que passam

## üîÑ Atualizando os Scrapers

Os sites alvo podem mudar sua estrutura HTML ao longo do tempo, exigindo atualiza√ß√µes nos scrapers.

### Sinais de que o Scraper Precisa de Atualiza√ß√£o

- Erros em s√©rie na pipeline
- Dados incompletos ou incorretos
- Timeout ao esperar por seletores

### Processo de Atualiza√ß√£o

1. **Analise o site manualmente**:
   - Abra o site em um navegador
   - Use as ferramentas de desenvolvedor (F12) para inspecionar os elementos

2. **Identifique as mudan√ßas**:
   - Compare os seletores CSS atuais com a nova estrutura
   - Identifique novos campos ou campos removidos

3. **Atualize o c√≥digo**:
   - Modifique os seletores em `olxScraper.js` ou `zapScraper.js`
   - Atualize a l√≥gica de extra√ß√£o conforme necess√°rio

4. **Teste localmente**:

   ```bash
   npm run scrape:olx  # ou scrape:zap
   ```

5. **Verifique os dados extra√≠dos**:

   ```bash
   cat data/results/olxResults.json | jq .
   # ou
   cat data/results/zapResults.json | jq .
   ```

## üîÑ Integra√ß√£o com o Reposit√≥rio Alvo

Este projeto envia dados para o reposit√≥rio QueroCAsa atrav√©s de Pull Requests autom√°ticos.

### Fluxo de Integra√ß√£o

1. Os scrapers coletam dados
2. A pipeline processa e merge os dados
3. Um PR √© criado para a branch `api` do reposit√≥rio alvo
4. Ap√≥s aprova√ß√£o, os dados s√£o integrados

### Testando a Integra√ß√£o Localmente

Se voc√™ precisar testar o fluxo completo localmente:

1. Clone o reposit√≥rio alvo:

   ```bash
   git clone https://github.com/user/querocasa.git
   ```

2. Execute os scrapers e gere os arquivos JSON:

   ```bash
   # No diret√≥rio do scraper
   npm run scrape
   ```

3. Copie os resultados para o reposit√≥rio alvo:

   ```bash
   cp data/results/*.json ../querocasa/data/results/
   ```

4. Execute os scripts de processamento:

   ```bash
   # No diret√≥rio do reposit√≥rio alvo
   node scripts/mergeResults.js
   ```

## üîß Troubleshooting para Desenvolvedores

### Recuperando de Falhas no Scraper

Se o scraper falhar repetidamente:

1. **Verifique as depend√™ncias do Puppeteer**:

   ```bash
   sudo apt-get install -y xvfb libxss1 libgtk-3-0 libnotify-dev libnss3 libx11-xcb1
   ```

2. **Ajuste o tempo de espera**:
   Aumente os tempos de timeout em `zapScraper.js` ou `olxScraper.js`:

   ```javascript
   await page.waitForSelector("elemento", { timeout: 20000 });
   ```

3. **Execute em modo n√£o-headless**:
   Modifique `browserProps` para:

   ```javascript
   const browserProps = {
     headless: false,
     // outras configura√ß√µes...
   };
   ```

4. **Adicione mais logs**:

   ```javascript
   console.log("Debug elemento:", await page.evaluate(() => {
     return document.querySelector("elemento") ? "encontrado" : "n√£o encontrado";
   }));
   ```

### Corrigindo Problemas de Depend√™ncias

Se houver problemas com depend√™ncias:

```bash
rm -rf node_modules
npm cache clean --force
npm install
```

### Monitoramento e Logs

Para adicionar mais logs detalhados quando estiver debugando:

```javascript
const DEBUG = process.env.DEBUG === 'true';

if (DEBUG) {
  console.log('Detalhes:', objeto);
}
```

Execute com:

```bash
DEBUG=true node scrapers/index.js zap 1000000
```
