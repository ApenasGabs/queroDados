name: Scrape OLX and Zap and push results

on:
  push:
    branches:
      - main
  schedule:
    - cron: "40 4 * * *"
  workflow_dispatch:

env:
  RESULTS_DIR: "data/results"
  QUEROCASA_DIR: "querocasa"
  MAX_RETRIES: 3
  RETRY_DELAY: 10

jobs:
  olx-scraper:
    runs-on: ubuntu-latest
    outputs:
      artifact-path: ${{ steps.upload-olx-artifact.outputs.artifact-path }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Install required system packages
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb libxss1 libgtk-3-0 libnotify-dev libnss3 libx11-xcb1
      - name: Create results directory
        run: mkdir -p data/results

      - name: Run OLX scraper with retries
        id: olx-scraper
        run: |
          set +e
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i of $MAX_RETRIES"
            Xvfb :99 -ac -screen 0 1280x1024x16 &
            export DISPLAY=:99
            if node scrapers/index.js olx ${{ secrets.MAX_PRICE }}; then
              echo "Scraping completed successfully"
              break
            else
              echo "Scraping failed on attempt $i"
              if [ $i -lt $MAX_RETRIES ]; then
                echo "Waiting $RETRY_DELAY seconds before retry..."
                sleep $RETRY_DELAY
              else
                echo "All attempts failed, creating empty results file"
                echo "[]" > data/results/olxResults.json
              fi
            fi
          done
          set -e

      - name: Validate OLX results
        run: |
          if [ -f "data/results/olxResults.json" ]; then
            if ! jq empty data/results/olxResults.json 2>/dev/null; then
              echo "Invalid JSON, creating empty array"
              echo "[]" > data/results/olxResults.json
            fi
          else
            echo "Results file not found, creating empty one"
            echo "[]" > data/results/olxResults.json
          fi

      - name: Save OLX results as an artifact
        id: upload-olx-artifact
        uses: actions/upload-artifact@v4
        with:
          name: olx-results
          path: data/results
          retention-days: 1

  zap-scraper:
    runs-on: ubuntu-latest
    outputs:
      artifact-path: ${{ steps.upload-zap-artifact.outputs.artifact-path }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install dependencies
        run: npm ci --prefer-offline

      - name: Install required system packages
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb libxss1 libgtk-3-0 libnotify-dev libnss3 libx11-xcb1
      - name: Create results directory
        run: mkdir -p data/results

      - name: Run Zap scraper with retries
        id: zap-scraper
        run: |
          set +e
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i of $MAX_RETRIES"
            Xvfb :99 -ac -screen 0 1280x1024x16 &
            export DISPLAY=:99
            if node scrapers/index.js zap ${{ secrets.MAX_PRICE }}; then
              echo "Scraping completed successfully"
              break
            else
              echo "Scraping failed on attempt $i"
              if [ $i -lt $MAX_RETRIES ]; then
                echo "Waiting $RETRY_DELAY seconds before retry..."
                sleep $RETRY_DELAY
              else
                echo "All attempts failed, creating empty results file"
                echo "[]" > data/results/zapResults.json
              fi
            fi
          done
          set -e

      - name: Validate Zap results
        run: |
          if [ -f "data/results/zapResults.json" ]; then
            if ! jq empty data/results/zapResults.json 2>/dev/null; then
              echo "Invalid JSON, creating empty array"
              echo "[]" > data/results/zapResults.json
            fi
          else
            echo "Results file not found, creating empty one"
            echo "[]" > data/results/zapResults.json
          fi

      - name: Save Zap results as an artifact
        id: upload-zap-artifact
        uses: actions/upload-artifact@v4
        with:
          name: zap-results
          path: data/results
          retention-days: 1

  download-and-update-repo:
    runs-on: ubuntu-latest
    needs: [olx-scraper, zap-scraper]
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Clone the target repository
        run: |
          git clone https://github.com/${{ secrets.TARGET_REPO_URL }}.git querocasa
        env:
          GITHUB_TOKEN: ${{ secrets.TARGET_REPO_PAT }}

      - name: Checkout to api branch and update
        run: |
          cd querocasa
          git fetch origin
          git checkout -b api origin/api || git checkout -b api
          git config pull.rebase false
          git pull origin api

      - name: Configure Git user
        run: |
          cd querocasa
          git config --global user.name "${{ secrets.GIT_USER_NAME }}"
          git config --global user.email "${{ secrets.GIT_USER_EMAIL }}"

      - name: Set up separate directories for old and new data
        run: |
          mkdir -p data/results_new
          mkdir -p querocasa/data/results

          echo "===== VERIFICANDO DADOS ANTIGOS EXISTENTES ====="
          if [ -f "querocasa/data/results/olxResults.json" ]; then
            echo "‚úÖ Arquivo olxResults.json encontrado"
            COUNT=$(grep -o "\"id\":" querocasa/data/results/olxResults.json | wc -l)
            echo "   Cont√©m aproximadamente $COUNT itens"
          else
            echo "‚ùå Arquivo olxResults.json n√£o encontrado - criando vazio"
            echo "[]" > querocasa/data/results/olxResults.json
          fi

          if [ -f "querocasa/data/results/zapResults.json" ]; then
            echo "‚úÖ Arquivo zapResults.json encontrado"
            COUNT=$(grep -o "\"id\":" querocasa/data/results/zapResults.json | wc -l)
            echo "   Cont√©m aproximadamente $COUNT itens"
          else
            echo "‚ùå Arquivo zapResults.json n√£o encontrado - criando vazio"
            echo "[]" > querocasa/data/results/zapResults.json
          fi

      - name: Download OLX artifact
        uses: actions/download-artifact@v4
        with:
          name: olx-results
          path: data/results_new

      - name: Download Zap artifact
        uses: actions/download-artifact@v4
        with:
          name: zap-results
          path: data/results_new

      - name: Move error screenshots to querocasa folder
        run: |
          echo "Movendo imagens de erro para o reposit√≥rio clonado..."
          mkdir -p querocasa/screenshots
          find data/results_new -name "*.png" -exec cp {} querocasa/screenshots/ \;

      - name: Verify downloaded artifacts
        run: |
          echo "===== VERIFICANDO ARTEFATOS BAIXADOS ====="
          cd data/results_new
          ls -la

          for platform in olx zap; do
            file="${platform}Results.json"
            echo "Verificando $file..."
            if [ ! -f "$file" ] || [ ! -s "$file" ]; then
              echo "‚ö†Ô∏è Arquivo $file ausente ou vazio - criando array vazio"
              echo "[]" > "$file"
            else
              if jq empty "$file" 2>/dev/null; then
                echo "‚úÖ Arquivo $file validado com sucesso"
                COUNT=$(grep -o "\"id\":" "$file" | wc -l)
                echo "   Cont√©m aproximadamente $COUNT itens"
              else
                echo "‚ùå Arquivo $file cont√©m JSON inv√°lido - substituindo por array vazio"
                echo "[]" > "$file"
              fi
            fi
          done

      - name: Install dependencies in querocasa
        run: |
          cd querocasa
          npm install --package-lock-only
          npm ci --prefer-offline

      - name: Validate scraped data
        run: |
          echo "Validando dados coletados..."
          cd querocasa
          if [ -f "scripts/validateData.js" ]; then
            if ! node scripts/validateData.js; then
              echo "::warning::Alguns problemas foram encontrados na valida√ß√£o"
            fi
          else
            echo "Script validateData.js n√£o encontrado, pulando valida√ß√£o"
          fi

      - name: Merge and update results
        run: |
          echo "===== MESCLANDO RESULTADOS ====="
          cd querocasa

          cat > run-merge.js <<'EOF'
          import { processPlatformResults, configurePaths } from './scripts/alaSQLmergeResults.js';

          const OLD_PATH = './data/results';
          const NEW_PATH = '../data/results_new';

          async function runMerge() {
            try {
              console.log('Configurando caminhos espec√≠ficos para o CI...');
              console.log(`OLD_PATH: ${OLD_PATH}`);
              console.log(`NEW_PATH: ${NEW_PATH}`);
              
              configurePaths(OLD_PATH, NEW_PATH);
              
              console.log('Iniciando processamento de OLX...');
              await processPlatformResults('olx');
              
              console.log('Iniciando processamento de ZAP...');
              await processPlatformResults('zap');
              
              console.log('Merge completo!');
            } catch (error) {
              console.error('Erro durante o merge:', error);
              process.exit(1);
            }
          }

          runMerge();
          EOF

          node run-merge.js
          echo "Resultados mesclados com sucesso!"

      - name: Verify merge results
        run: |
          echo "===== VERIFICANDO RESULTADOS DO MERGE ====="
          cd querocasa/data/results

          # Fun√ß√£o melhorada para verificar arquivos JSON com retry
          verify_json_file_with_retry() {
            local file=$1
            local max_attempts=3  # N√∫mero m√°ximo de tentativas
            local attempt=1
            local retry_delay=5   # Tempo entre tentativas (segundos)
            local success=false
            
            echo "üîç Analisando $file (com retry autom√°tico)..."
            
            while [ $attempt -le $max_attempts ] && [ "$success" != "true" ]; do
              if [ $attempt -gt 1 ]; then
                echo "üîÑ Tentativa $attempt de $max_attempts para verificar $file"
                echo "   Aguardando $retry_delay segundos antes de tentar novamente..."
                sleep $retry_delay
              fi
              
              # Verificar se o arquivo existe
              if [ ! -f "$file" ]; then
                echo "‚ùå Arquivo $file n√£o encontrado ap√≥s o merge!"
                if [ $attempt -lt $max_attempts ]; then
                  ((attempt++))
                  continue
                else
                  echo "‚ö†Ô∏è Criando arquivo vazio ap√≥s $max_attempts tentativas falhas"
                  echo "[]" > "$file"
                  success=true
                  break
                fi
              fi
              
              # Verificar tamanho do arquivo
              local file_size=$(stat -c %s "$file")
              echo "üìä Tamanho do arquivo: $file_size bytes"
              
              if [ "$file_size" -lt 5 ]; then
                echo "‚ùå Arquivo $file est√° vazio ou muito pequeno!"
                echo "[]" > "$file"
                echo "‚úÖ Arquivo substitu√≠do por um array vazio v√°lido"
                success=true
                break
              fi
              
              # Verificar se √© um JSON v√°lido
              local jq_result
              if jq empty "$file" > /dev/null 2>&1; then
                echo "‚úÖ Arquivo $file √© um JSON v√°lido"
                
                # Se chegou aqui, o JSON √© v√°lido
                local total=$(jq 'length' "$file")
                echo "üìä Total de propriedades em $file: $total"
                
                # Verificar n√∫mero de itens com IDs
                if jq -e 'map(select(.id != null)) | length' "$file" > /dev/null; then
                  local ids_count=$(jq 'map(select(.id != null)) | length' "$file")
                  echo "üè∑Ô∏è N√∫mero de itens com IDs: $ids_count"
                  
                  if [ $ids_count -lt $total ]; then
                    echo "‚ö†Ô∏è Aten√ß√£o: h√° $(($total - $ids_count)) itens sem ID!"
                  fi
                  
                  # Mostrar os primeiros IDs como amostra
                  echo "üîë Amostra de IDs:"
                  jq -r 'map(select(.id != null)) | .[0:3] | .[].id' "$file" 2>/dev/null || echo "Nenhum ID encontrado"
                else
                  echo "‚ö†Ô∏è Nenhum item com ID encontrado!"
                fi
                
                # Verificar se h√° propriedades sem links
                local no_link_count=$(jq 'map(select(.link == null)) | length' "$file")
                if [ "$no_link_count" -gt 0 ]; then
                  echo "‚ö†Ô∏è H√° $no_link_count itens sem link!"
                fi
                
                success=true
                break
              else
                # JSON inv√°lido - tenta corrigir
                jq_result=$(jq empty "$file" 2>&1)
                echo "‚ùå Arquivo $file cont√©m JSON inv√°lido na tentativa $attempt!"
                echo "üîç Erro detalhado: $jq_result"
                
                # Diagn√≥stico adicional para encontrar o problema
                echo "üîé Tentando localizar o problema..."
                
                # Verificar se o in√≠cio e fim s√£o v√°lidos (deve come√ßar com [ e terminar com ])
                local first_char=$(head -c 1 "$file")
                local last_char=$(tail -c 2 "$file" | head -c 1)
                
                if [ "$first_char" != "[" ]; then
                  echo "‚ùå O arquivo n√£o come√ßa com '['. Primeiro caractere: $first_char"
                fi
                
                if [ "$last_char" != "]" ]; then
                  echo "‚ùå O arquivo n√£o termina com ']'. √öltimo caractere: $last_char"
                fi
                
                # Verificar problemas comuns
                grep -n ",]" "$file" | head -5 | while read line; do
                  echo "üî¥ V√≠rgula antes do fechamento de array na linha: $line"
                done
                
                grep -n ",}" "$file" | head -5 | while read line; do
                  echo "üî¥ V√≠rgula antes do fechamento de objeto na linha: $line"
                done
                
                # Tentar recuperar o arquivo com jq
                echo "üîÑ Tentativa de recupera√ß√£o autom√°tica..."
                if jq -e 'if type == "array" then . else [] end' "$file" > "${file}.fixed" 2>/dev/null; then
                  mv "${file}.fixed" "$file"
                  echo "‚úÖ Arquivo recuperado com sucesso!"
                  
                  # Verificar se a recupera√ß√£o funcionou
                  if jq empty "$file" > /dev/null 2>&1; then
                    echo "‚úÖ Recupera√ß√£o bem-sucedida, JSON agora √© v√°lido"
                    success=true
                    break
                  else
                    echo "‚ùå Recupera√ß√£o n√£o foi suficiente, ainda temos problemas"
                  fi
                else
                  echo "‚ùå Tentativa de recupera√ß√£o falhou."
                  
                  # Na √∫ltima tentativa, criar array vazio
                  if [ $attempt -eq $max_attempts ]; then
                    echo "‚ö†Ô∏è Chegamos ao limite de tentativas. Criando array vazio..."
                    echo "[]" > "$file"
                    echo "‚úÖ Arquivo substitu√≠do por um array vazio v√°lido"
                    success=true
                    break
                  fi
                fi
              fi
              
              # Preparar para pr√≥xima tentativa
              ((attempt++))
              
              # Espera adicional com sincroniza√ß√£o de disco antes da pr√≥xima tentativa
              echo "üîÑ For√ßando sincroniza√ß√£o do sistema de arquivos..."
              sync
            done
            
            if [ "$success" != "true" ]; then
              echo "‚ùå Todas as tentativas falharam para $file. Criando array vazio de emerg√™ncia."
              echo "[]" > "$file"
              echo "‚úÖ Arquivo substitu√≠do por um array vazio v√°lido"
            fi
            
            return 0
          }

          # Validando os arquivos com retry
          echo "üîç Analisando olxResults.json ap√≥s o merge:"
          verify_json_file_with_retry "olxResults.json"

          echo "üîç Analisando zapResults.json ap√≥s o merge:"
          verify_json_file_with_retry "zapResults.json"

          # Verifica√ß√£o final para garantir que ambos os arquivos s√£o v√°lidos
          echo "üß™ Verifica√ß√£o final dos arquivos processados:"
          for file in olxResults.json zapResults.json; do
            if ! jq empty "$file" 2>/dev/null; then
              echo "‚ùå FALHA: $file ainda cont√©m JSON inv√°lido ap√≥s todas as tentativas!"
              echo "‚ö†Ô∏è Conte√∫do de emerg√™ncia sendo aplicado..."
              echo "[]" > "$file"
              echo "‚úÖ Arquivo $file definido como array vazio"
              export $(echo "${file%%Results.json}_VALID=false" | tr '[:lower:]' '[:upper:]')
            else
              echo "‚úÖ Arquivo $file validado com sucesso"
              export $(echo "${file%%Results.json}_VALID=true" | tr '[:lower:]' '[:upper:]')
            fi
          done

      - name: Update coordinates
        run: |
          echo "Atualizando coordenadas..."
          cd querocasa
          if [ -f "scripts/updateCoordinates.js" ]; then
            node scripts/updateCoordinates.js ${{ secrets.GEOCODE_HERE_API_KEY }} || echo "Erro ao atualizar coordenadas"
          else
            echo "Script updateCoordinates.js n√£o encontrado, pulando etapa"
          fi

      - name: Define branch name
        run: |
          # Usar um nome que muda apenas mensalmente para reusar PRs por um m√™s
          MONTH_YEAR=$(date +'%Y-%m')
          BRANCH_NAME="update/data-monthly-$MONTH_YEAR"
          echo "branch_name=$BRANCH_NAME" >> $GITHUB_ENV
          echo "Usando branch: $BRANCH_NAME"
      - name: Set current date
        run: |
          # Configurando timezone para Bras√≠lia (BRT)
          export TZ="America/Sao_Paulo"
          echo "CURRENT_DATE=$(date +'%Y-%m-%d')" >> $GITHUB_ENV
          echo "FORMATTED_DATE=$(date +'%d/%m/%Y')" >> $GITHUB_ENV
          echo "FULL_DATE=$(date +'%d/%m/%Y √†s %H:%M (BRT)')" >> $GITHUB_ENV

      - name: Generate summary
        if: env.should_skip != 'true'
        run: |
          cd querocasa
          echo "### üîÑ Resumo do Merge" > merge-summary.md
          echo "" >> merge-summary.md
          echo "_üìÖ Gerado em: **${{ env.FULL_DATE }}**_" >> merge-summary.md

          for file in data/results/*.json; do
            platform=$(basename "$file" Results.json)
            platform_upper=${platform^^}

            # Ignorar arquivos de erro ao contar resultados
            if [[ "$platform" == "olxErrors" || "$platform" == "zapErrors" ]]; then
              continue
            fi

            total=$(jq 'length' "$file")
            with_ids=$(jq 'map(select(.id != null)) | length' "$file")

            added=$(jq 'map(select(.__status == "added")) | length' "$file")
            updated=$(jq 'map(select(.__status == "updated")) | length' "$file")
            removed=$(jq 'map(select(.__status == "removed")) | length' "$file")

            echo "#### ${platform_upper}" >> merge-summary.md
            echo "- üÜï Novos im√≥veis adicionados: ${added:-N/A}" >> merge-summary.md
            echo "- ‚ôªÔ∏è Im√≥veis atualizados: ${updated:-N/A}" >> merge-summary.md
            echo "- üõë Im√≥veis removidos: ${removed:-N/A}" >> merge-summary.md
            echo "- üì¶ Total ap√≥s merge: $total" >> merge-summary.md
            echo "" >> merge-summary.md
          done

          echo "### üó∫Ô∏è Coordenadas geogr√°ficas" >> merge-summary.md
          echo "- üìç Total de bairros identificados: ${{ env.TOTAL_NEIGHBORHOODS }}" >> merge-summary.md
          echo "- ‚úÖ Coordenadas atualizadas: ${{ env.COORDINATES_UPDATED }}" >> merge-summary.md
          echo "" >> merge-summary.md
          echo "### ‚ö†Ô∏è Erros durante o scraping" >> merge-summary.md
          echo "" >> merge-summary.md

          # Processar logs de erro do Zap
          if [ -f "data/results/zapErrors.json" ]; then
            echo "#### ZAP Im√≥veis" >> merge-summary.md
            erro_count=$(jq 'length' data/results/zapErrors.json)
            echo "Encontrados $erro_count erros durante o scraping" >> merge-summary.md
            
            # Listar os 5 erros mais recentes
            echo "<details>" >> merge-summary.md
            echo "<summary>Detalhes dos √∫ltimos erros</summary>" >> merge-summary.md
            echo "" >> merge-summary.md
            
            jq -r 'sort_by(.timestamp) | reverse | .[0:5] | .[] | "**[\(.timestamp)]** \(.message)\n\n```\n\(.details.errorMessage // "Sem detalhes")\n```\n"' data/results/zapErrors.json >> merge-summary.md
            
            echo "</details>" >> merge-summary.md
          fi

          # Processar logs de erro do OLX (se existirem)
          if [ -f "data/results/olxErrors.json" ]; then
            echo "#### OLX" >> merge-summary.md
            erro_count=$(jq 'length' data/results/olxErrors.json)
            echo "Encontrados $erro_count erros durante o scraping" >> merge-summary.md
            
            echo "<details>" >> merge-summary.md
            echo "<summary>Detalhes dos √∫ltimos erros</summary>" >> merge-summary.md
            echo "" >> merge-summary.md
            
            jq -r 'sort_by(.timestamp) | reverse | .[0:5] | .[] | "**[\(.timestamp)]** \(.message)\n\n```\n\(.details.errorMessage // "Sem detalhes")\n```\n"' data/results/olxErrors.json >> merge-summary.md
            
            echo "</details>" >> merge-summary.md
          fi

          echo "### üñºÔ∏è Capturas de Erro" >> merge-summary.md
          COMMIT_HASH=$(git rev-parse HEAD) 
          for img in screenshots/*.png; do
            [ -f "$img" ] && echo "![Erro](https://raw.githubusercontent.com/ApenasGabs/querocasa/${COMMIT_HASH}/${img})" >> merge-summary.md
          done

      - name: Create or update Pull Request
        if: env.should_skip != 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.TARGET_REPO_PAT }}
          path: querocasa
          commit-message: ":rocket: Atualiza√ß√£o autom√°tica de dados [${{ env.CURRENT_DATE }}]"
          branch: ${{ env.branch_name }}
          title: "ü§ñ Atualiza√ß√£o autom√°tica de dados - ${{ env.FORMATTED_DATE }}"
          body-path: querocasa/merge-summary.md
          base: api
          # update-branch: true
